\subsection{Inductive Monitoring System (IMS)}
\label{subsec:spec:IMS}
IMS автоматически строит базу знаний для последующего мониторинга состояния системы на основе номинальных данных, собранных непосредственно во время работы системы либо её симуляций. IMS использует машинное обучение и методы интеллектуального анализа данных для описания типичного для системы поведения путём извлечения из исходных данных основных классов. В частности, IMS использует кластеризацию для группировки постоянно встречающихся последовательностей в обучающей выборке. Кластеризация~---~семейство алгоритмов, относящееся к обучению без учителя, упорядочивающих объекты в сравнительно однородные группы (\textit{кластеры}). Идея метода IMS проистекает из двух алгоритмов кластеризации: алгоритма K-средних (K-means)~\cite{BradleyKMeans} и DBSCAN~\cite{EsterDensityBasedClustering} (кластеризация на основе плотности групп точек). Метод разработан Дэвидом Иверсоном (NASA Ames Research Center) и описан им в~\cite{IversonISHM}.

Базовой структурой данных для этого метода является вектор параметров системы. Пример подобного вектора приведён в таблице~\ref{tab:spec:IMS:SampleVector}. Каждый вектор содержит упорядоченный набор параметров, полученный системой мониторинга в процессе сбора телеметрии. Он также может содержать производные от измерений параметры. Векторы параметров системы представляют собой точки в $N$-мерном пространстве, которые IMS группирует в кластеры. Значения вектора могут быть получены подсистемой сбора данных как одновременно, либо быть собранными в вектор из нескольких измерений в течение некоторого периода времени. Размер и конкретные параметры вектора определяются вручную в соответствии с поставленной задачей мониторинга.

\begin{table}[h]
\caption{Пример вектора данных IMS}
\label{tab:spec:IMS:SampleVector}

\begin{tabular}{|C{55pt}|C{50pt}|C{55pt}|C{50pt}|C{75pt}|C{75pt}|}
\hline
Давление A & Позиция клапана 1 & Давление B & Позиция клапана 2 & Температура 1 & Температура 2 \\
\hline
2857.2 & 86.4\% & 1218.4 & 96.2\% & 49.8 & 37.6 \\
\hline
\end{tabular}
\end{table}

IMS обрабатывает обучающую выборку, форматируя исходные данные в соответствии с заданной структурой вектора параметров, и строит базу знаний из кластеров. Пример подобного кластера приведён в таблице~\ref{tab:spec:IMS:SampleCluster}. Каждый кластер определяет диапазон допустимых значений всех переменных для входного вектора данных. Вектор верхней границы и вектор нижней границы в кластере могут быть представлены, как углы минимального ограничивающего гиперкуба в $N$-мерном пространстве. Точки, попадающие внутрь этого гиперкуба либо в его окрестность, классифицируются алгоритмом как относящиеся к номинальному режиму работы системы, так как гиперкуб определяется исходя из номинальных данных. Данный подход схож с интервальной диагностикой, когда строится математическая модель системы, и определяются допустимые диапазоны изменения каждой переменной, но не требует знаний о характере и устройстве системы.

\begin{table}[h]
\caption{Пример кластера IMS}
\label{tab:spec:IMS:SampleCluster}

\begin{tabular}{|C{55pt}|C{55pt}|C{50pt}|C{55pt}|C{50pt}|C{75pt}|C{75pt}|}
\cline{2-7}
\multicolumn{1}{c|}{} & Давление A & Позиция клапана 1 & Давление B & Позиция клапана 2 & Температура 1 & Температура 2 \\
\hline
Верхняя граница & 2857.2 & 86.4\% & 1218.4 & 96.2\% & 49.8 & 37.6 \\
\hline
Нижная граница & 2857.2 & 86.4\% & 1218.4 & 96.2\%  & 49.8 & 37.6 \\
\hline
\end{tabular}
\end{table}

IMS начинает процесс обучения с пустой базы кластеров. Метод считывает элементы обучающей выборки и формирует из них в векторы. Первый вектор добавляется в базу, как исходный кластер. Каждый последующий вектор сравнивается с содержимым базы кластеров с тем, чтобы найти ближайший к этому вектору кластер. Для определения расстояния между вектором и кластером могут быть использованы различные метрики, например, Евклидово расстояние. Для того, чтобы найти расстояние от вектора до кластера, необходимо выбрать точку в кластере, до которой оно будет измерено. Одним из вариантов, основанным на алгоритме К-средних~\cite{BradleyKMeans}, является выбор центроида кластера, который рассчитывается как среднее между нижней и верхней границами. Для каждого нового вектора из обучающей выборки IMS находит в базе ближайший к нему кластер. Далее определяется, попадает ли вектор внутрь ограничивающего гиперкуба данного кластера или в его окрестность. Как и в кластеризации на основе плотности точек~\cite{EsterDensityBasedClustering}, вводится пороговое значение $\varepsilon$, заданное пользователем, которое определяет максимальное допустимое расстояние между вектором и кластером. На основе этого расстояния алгоритм определяет, стоит ли добавлять вектор в кластер. Если вектор достаточно близок (расстояние меньше или равно $\varepsilon$), границы кластера раздвигаются, чтобы вместить его. Если же расстояние превышает $\varepsilon$, создаётся новый кластер и добавляется в базу. Процесс обучения повторяется до тех пор, пока не будет обработана вся обучающая выборка. Малое значение $\varepsilon$ приводит к созданию небольших по размеру кластеров, что обеспечивает более точный контроль, но значительно увеличивает размер базы знаний, делая невозможным мониторинг системы в реальном времени. Значение $\varepsilon$ может быть подобрано таким образом, чтобы обеспечить баланс между скоростью работы и точностью контроля.

Блок-схема процесса обучения приведена в приложении~\ref{app:IMS:TrainingScheme}.

Результатом обработки IMS обучающей выборки является модель системы в виде базы кластеров, характеризующая работу системы в номинальных режимах, отображённых в исходных данных. В дополнение к этому, каждый кластер определяет ограничения на значения каждого из параметров в векторе.

Для использования получившейся базы кластеров для мониторинга состояния системы IMS формирует векторы из приходящих данных и запрашивает базу на предмет ближайшего к каждому входному вектору кластера. Наиболее быстрый способ проверки требует, чтобы все векторы находились внутри по крайней мере одного из кластеров внутри базы (значения всех параметров должны находиться внутри диапазонов, определённых границами кластера). Такой способ устраняет необходимость вычисления расстояний. Более информативная техника мониторинга находит ближайший к входному вектору кластер и показывает пользователю расстояние между ними. Это даёт оператору представление, насколько поведение системы отклоняется от нормального, представленного в обучающей выборке. Метод может учитывать неполноту обучающей выборки и неточности измерений путём задания порогового значения $\varepsilon$.

Блок-схема процесса мониторинга приведена в приложении~\ref{app:IMS:MonitoringScheme}.

Преимущества метода:
\begin{itemize}
	\item не требует больших вычислительных ресурсов, способен работать в реальном времени;
	\item предоставляет оператору численную характеристику аномальности вектора измерений;
	\item не имеет ограничений на закон распределения входных данных;
	\item не требует никаких знаний о предметной области, природе системы, её внутреннем устройстве, характеристиках входных данных, что обеспечивает универсальность и возможность применения к широкому спектру технических систем.
\end{itemize}

Недостатки:
\begin{itemize}
	\item метод неустойчив по отношению к шуму и аномалиям в обучающей выборке; 
	\item вектор входных данных может содержать только непрерывные переменные;
	\item стандартный вариант метода рассчитывает расстояние до центра кластера, что снижает точность мониторинга.
\end{itemize}